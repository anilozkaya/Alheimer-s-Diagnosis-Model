{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad14d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install SimpleITK\n",
    "pip install dltk\n",
    "pip install nipype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573fbc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces import fsl\n",
    "from nipype.testing import example_data\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from dltk.io.augmentation import *\n",
    "from dltk.io.preprocessing import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import skimage\n",
    "from skimage import data\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d4c68a",
   "metadata": {},
   "source": [
    "# Generate CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8851a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is no a csv file for the data, it can be created by using the code below. Data should be in folders according to their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea079c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(dir_name=r'/content/drive/Othercomputers/MSI/Documents/BitirmeTezi/Uygulama/ADNI1_Baseline_3T/ADNI-yedek/test'):\n",
    "    \n",
    "    Images = []\n",
    "    Classes = []\n",
    "    m_names=[]\n",
    "    #for j in ['/train','/test']:\n",
    "    for label_name in os.listdir(dir_name):\n",
    "        for img_file_name in os.listdir('/'.join([dir_name, label_name])):\n",
    "\n",
    "            m_names.append([img_file_name, label_name])\n",
    "\n",
    "    return m_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6cf9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_names= get_images(\"/content/drive/Othercomputers/MSI/Documents/BitirmeTezi/Uygulama/ADNI1_Baseline_3T/ADNI-yedek/test\")\n",
    "\n",
    "df = pd.DataFrame(m_names, columns=['img_file_name', 'label_name']) # create a dataframe from match list\n",
    "df.to_csv(\"test.csv\", index=False) # create csv from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9c31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_names= get_images(\"/content/drive/Othercomputers/MSI/Documents/BitirmeTezi/Uygulama/ADNI1_Baseline_3T/ADNI-yedek/train\")\n",
    "\n",
    "df = pd.DataFrame(m_names, columns=['img_file_name', 'label_name']) # create a dataframe from match list\n",
    "df.to_csv(\"train.csv\", index=False) # create csv from df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d6f1c9",
   "metadata": {},
   "source": [
    "# Prepare The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bf499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "#Unzip the FSL zip files\n",
    "for filename in os.listdir('/content/drive/Othercomputers/MSI/Documents/BitirmeTezi/Uygulama/ADNI1_Baseline_3T/ADNI-yedek/skull_stripped_test'): \n",
    "  with gzip.open(os.path.join('/content/drive/Othercomputers/MSI/Documents/BitirmeTezi/Uygulama/ADNI1_Baseline_3T/ADNI-yedek/skull_stripped_test', filename), 'rb') as f_in:\n",
    "      with open(os.path.join('/content/drive/MyDrive/preprocessed/test_unzipped', filename.replace(\".gz\",\"\")), 'wb') as f_out:\n",
    "         shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d78fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('/content/drive/Othercomputers/MSI/Documents/BitirmeTezi/Uygulama/ADNI1_Baseline_3T/ADNI-yedek/skull_stripped_train'): \n",
    "  with gzip.open(os.path.join('/content/drive/Othercomputers/MSI/Documents/BitirmeTezi/Uygulama/ADNI1_Baseline_3T/ADNI-yedek/skull_stripped_train', filename), 'rb') as f_in:\n",
    "      with open(os.path.join('/content/drive/MyDrive/preprocessed/train_unzipped', filename.replace(\".gz\",\"\")), 'wb') as f_out:\n",
    "         shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa9f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For The Training Data\n",
    "\n",
    "# prepare and organize the images\n",
    "path='/content/drive/MyDrive/preprocessed/train_unzipped'\n",
    "for filename in os.listdir(path):   \n",
    "        complete_file_path = os.path.join(path, filename)  # filename\n",
    "        # load sitk image\n",
    "        sitk_moving = sitk.ReadImage(complete_file_path)\n",
    "        #sitk_moving = resample_img(sitk_moving)\n",
    "        t1 = sitk.GetArrayFromImage(sitk_moving)\n",
    "        # Resizing image to [128, 256, 256] required padding\n",
    "        #t1_padded = resize_image_with_crop_or_pad(t1, [128, 128, 128], mode='symmetric')\n",
    "        sitk_moving=skimage.transform.resize(t1, [128, 128, 128])\n",
    "        t1_norm_zo = normalise_zero_one(sitk_moving) #Diğer koddan alındı\n",
    "        \n",
    "        # Crop to [64, 64, 64]\n",
    "        #t1_cropped = resize_image_with_crop_or_pad(t1, [64, 64, 64], mode='symmetric')\n",
    "\n",
    "\n",
    "        # Add a feature dimension and normalise\n",
    "        #t1_norm = np.expand_dims(normalise_one_one(t1_slice), axis=-1)\n",
    "\n",
    "        # Randomly flip the image along axis 1\n",
    "        #t1_flipped = flip(t1_norm_zo.copy(), axis=1)\n",
    "\n",
    "        # Add a Gaussian offset (independently for each channel)\n",
    "        #t1_offset = add_gaussian_offset(t1_norm_zo.copy(), sigma=0.5)\n",
    "\n",
    "        # Add Gaussian noise\n",
    "        #t1_noise = add_gaussian_noise(t1_norm_zo.copy(), sigma=0.25)\n",
    "\n",
    "        # Elastic transforms \n",
    "        #t1_trans_low_s = elastic_transform(t1_norm.copy(), alpha=[1, 1e5, 1e5], sigma=[1, 10, 10])\n",
    "        #t1_trans_high_s = elastic_transform(t1_norm.copy(), alpha=[10, 2e6, 2e6], sigma=[1, 25, 25])\n",
    "\n",
    "\n",
    "        new_image=sitk.GetImageFromArray(t1_norm_zo)\n",
    "        \n",
    "        # prepare the destination path\n",
    "        complete_new_path = os.path.join('/content/drive/MyDrive/preprocessed/train', \n",
    "                                        filename)  #filename\n",
    "        sitk.WriteImage(new_image, complete_new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c57f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For The Test Data\n",
    "\n",
    "\n",
    "# prepare and organize the images\n",
    "path='/content/drive/MyDrive/preprocessed/test_unzipped'\n",
    "#for files in os.walk(DATABASE):\n",
    "for filename in os.listdir(path):   \n",
    "    #for filename in os.listdir(os.path.join(path, classname)):\n",
    "        complete_file_path = os.path.join(path, filename)  # filename\n",
    "        # load sitk image\n",
    "        sitk_moving = sitk.ReadImage(complete_file_path)\n",
    "        #sitk_moving = resample_img(sitk_moving)\n",
    "        # Resizing image to [128, 256, 256] required padding\n",
    "        \n",
    "        t1 = sitk.GetArrayFromImage(sitk_moving)\n",
    "        #t1_padded = resize_image_with_crop_or_pad(t1, [128, 128, 128], mode='symmetric')\n",
    "\n",
    "        sitk_moving=skimage.transform.resize(t1, [128, 128, 128])\n",
    "        t1_norm_zo = normalise_zero_one(sitk_moving) #Diğer koddan alındı\n",
    "        # Crop to [64, 64, 64]\n",
    "        #t1_cropped = resize_image_with_crop_or_pad(t1, [64, 64, 64], mode='symmetric')\n",
    "\n",
    "\n",
    "        # Add a feature dimension and normalise\n",
    "        #t1_norm = np.expand_dims(normalise_one_one(t1_slice), axis=-1)\n",
    "\n",
    "        # Randomly flip the image along axis 1\n",
    "        #t1_flipped = flip(t1_norm_zo.copy(), axis=1)\n",
    "\n",
    "        # Add a Gaussian offset (independently for each channel)\n",
    "        #t1_offset = add_gaussian_offset(t1_norm_zo.copy(), sigma=0.5)\n",
    "\n",
    "        # Add Gaussian noise\n",
    "        #t1_noise = add_gaussian_noise(t1_norm_zo.copy(), sigma=0.25)\n",
    "\n",
    "        # Elastic transforms \n",
    "        #t1_trans_low_s = elastic_transform(t1_norm.copy(), alpha=[1, 1e5, 1e5], sigma=[1, 10, 10])\n",
    "        #t1_trans_high_s = elastic_transform(t1_norm.copy(), alpha=[10, 2e6, 2e6], sigma=[1, 25, 25])\n",
    "\n",
    "\n",
    "        new_image=sitk.GetImageFromArray(t1_norm_zo)\n",
    "\n",
    "\n",
    "        # prepare the destination path\n",
    "        complete_new_path = os.path.join('/content/drive/MyDrive/preprocessed/test', \n",
    "                                        filename)  #filename\n",
    "        sitk.WriteImage(new_image, complete_new_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9d2e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = r'/content/drive/MyDrive/preprocessed/train'\n",
    "str = \"_brain\"\n",
    "for filename in os.listdir(rootdir):\n",
    "    if str in filename:    \n",
    "        filepath = os.path.join(rootdir, filename)\n",
    "        newfilepath = os.path.join(rootdir, filename.replace(str, \"\"))\n",
    "        os.rename(filepath, newfilepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61102c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = r'/content/drive/MyDrive/preprocessed/test'\n",
    "str = \"_brain\"\n",
    "for filename in os.listdir(rootdir):\n",
    "    if str in filename:    \n",
    "        filepath = os.path.join(rootdir, filename)\n",
    "        newfilepath = os.path.join(rootdir, filename.replace(str, \"\"))\n",
    "        os.rename(filepath, newfilepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0b466e",
   "metadata": {},
   "source": [
    "# Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3af139",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install monai\n",
    "pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910712f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "\n",
    "import monai\n",
    "from monai.data import ImageDataset\n",
    "from monai.transforms import AddChannel, Compose, RandRotate90, Resize, ScaleIntensity, EnsureType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5aa5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import summary\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7efd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_class = {\n",
    "    'NC': 0,\n",
    "    'MCI': 1,\n",
    "    'AD': 2,\n",
    "    #Extra classes can be added\n",
    "    #'NewClass':3\n",
    "    \n",
    "}\n",
    "class_to_label = {v: k for k, v in label_to_class.items()}\n",
    "n_classes = len(label_to_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db112b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "monai.config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "images = []\n",
    "labels=[]\n",
    "image_labels= pd.read_csv(\"/content/drive/MyDrive/train.csv\")\n",
    "image_labels = image_labels.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "for index in range(159):\n",
    "  labels.append(label_to_class[image_labels.iloc[index, 1]])\n",
    "  images.append(os.path.join(\"/content/drive/MyDrive/preprocessed/train\",image_labels.iloc[index,0])) \n",
    "\n",
    "labels = np.array(labels)\n",
    "image_file_names=image_labels.iloc[index,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9955adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6054d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781efca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=50\n",
    "#split için değişken oluştur\n",
    "\n",
    "# Define Training and Validation transforms\n",
    "train_transforms = Compose([ScaleIntensity(), AddChannel(), RandRotate90(), EnsureType()])  \n",
    "val_transforms = Compose([ScaleIntensity(), AddChannel(),  EnsureType()])   \n",
    "\n",
    "# Define image dataset, data loader\n",
    "check_ds = ImageDataset(image_files=images, labels=labels,transform=train_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=2, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "im, label = monai.utils.misc.first(check_loader)\n",
    "print(type(im), im.shape, label)\n",
    "\n",
    "# create a training data loader\n",
    "train_ds = ImageDataset(image_files=images[:144], labels=labels[:144], transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=7, shuffle=True, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "# create a validation data loader\n",
    "val_ds = ImageDataset(image_files=images[-15:], labels=labels[-15:], transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=5, shuffle=True, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "# Create DenseNet121, CrossEntropyLoss and Adam optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = monai.networks.nets.DenseNet121(spatial_dims=3,in_channels=1, out_channels=3 ).to(device)  \n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-7 ) \n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-5 , steps_per_epoch=len(train_loader), epochs=num_epochs)\n",
    "# start a typical PyTorch training\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33021dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "batch_size = 16\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14295a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir /content/runs/RunFileMustBeAdded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e162d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_model_training_loss_ls = []\n",
    "validation_model_training_accuracy_ls = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "      print(\"-\" * 10)\n",
    "      print(f\"epoch {epoch + 1}/{num_epochs}\")\n",
    "      model.train()\n",
    "      epoch_loss = 0\n",
    "      epoch_val_loss=0\n",
    "      step = 0\n",
    "      val_step=0\n",
    "      for batch_data in train_loader:\n",
    "          step += 1\n",
    "          inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "          optimizer.zero_grad()\n",
    "          outputs = model(inputs)\n",
    "          loss = loss_function(outputs, labels)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          scheduler.step()\n",
    "          curr_lr = optimizer.param_groups[0][\"lr\"]\n",
    "          epoch_loss += loss.item()\n",
    "          epoch_len = len(train_ds) // train_loader.batch_size\n",
    "          print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "          writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "          writer.add_scalar(\"learning_rate\",  curr_lr, epoch_len * epoch + step)\n",
    "      epoch_loss /= step\n",
    "      epoch_loss_values.append(epoch_loss)\n",
    "      print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "      #writer.add_scalar(\"total_train_loss\", epoch_loss, epoch_len * epoch + step)\n",
    "\n",
    "      if (epoch + 1) % val_interval == 0:\n",
    "          model.eval()\n",
    "          with torch.no_grad():\n",
    "              num_correct = 0.0\n",
    "              metric_count = 0\n",
    "              for val_data in val_loader:\n",
    "                  val_step=val_step+1\n",
    "                  val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                  val_outputs = model(val_images)\n",
    "                  value = torch.eq(val_outputs.argmax(dim=1), val_labels)\n",
    "                  metric_count += len(value)\n",
    "                  num_correct += value.sum().item()\n",
    "                  \n",
    "                  validation_loss_local_train_fn = loss_function(val_outputs, val_labels)##Doğru mu?\n",
    "                  #validation_model_training_loss_ls.append(validation_loss_local_train_fn.item())##\n",
    "                  epoch_val_loss += validation_loss_local_train_fn.item()\n",
    "                  print(f\"{step}/{epoch_len}, val_loss: {validation_loss_local_train_fn.item():.4f}\")\n",
    "                  writer.add_scalar(\"val_loss\", validation_loss_local_train_fn.item(), epoch_len * epoch + step)\n",
    "              metric = num_correct / metric_count\n",
    "              metric_values.append(metric)\n",
    "              epoch_val_loss /= val_step\n",
    "              epoch_loss_values.append(epoch_val_loss)\n",
    "              print(f\"epoch {epoch + 1} average validation loss: {epoch_val_loss:.4f}\")\n",
    "              \n",
    "              if metric > best_metric:\n",
    "                  best_metric = metric\n",
    "                  best_metric_epoch = epoch + 1\n",
    "                  torch.save(model.state_dict(), \"/content/drive/MyDrive/best_metric_files/best_metric_model_classification3d_array.pth\")\n",
    "                  print(\"saved new best metric model\")\n",
    "              print(\n",
    "                  \"current epoch: {} current accuracy: {:.4f} best accuracy: {:.4f} at epoch {}\".format(\n",
    "                      epoch + 1, metric, best_metric, best_metric_epoch\n",
    "                  )\n",
    "              )\n",
    "              writer.add_scalar(\"val_accuracy\", metric, epoch + 1)\n",
    "              \n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bcec2c",
   "metadata": {},
   "source": [
    "# Evaluation Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf2bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import monai\n",
    "from monai.data import CSVSaver, ImageDataset\n",
    "from monai.transforms import AddChannel, Compose, Resize, ScaleIntensity, EnsureType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52604ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "monai.config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "image_labels= pd.read_csv(\"/content/drive/MyDrive/test.csv\")\n",
    "#labels = np.array([], dtype=np.int64)\n",
    "for index in range(40):\n",
    "  labels.append(label_to_class[image_labels.iloc[index, 1]])\n",
    "  images.append(os.path.join(\"/content/drive/MyDrive/preprocessed/test\",\n",
    "                                    image_labels.iloc[index,0]))  #image_labels.iloc[index,1],\n",
    "\n",
    "labels = np.array(labels)\n",
    "# Define transforms for image\n",
    "val_transforms = Compose([ScaleIntensity(), AddChannel(),  EnsureType()]) \n",
    "\n",
    "# Define image dataset\n",
    "val_ds = ImageDataset(image_files=images, labels=labels, transform=val_transforms, image_only=False)\n",
    "# create a validation data loader\n",
    "val_loader = DataLoader(val_ds, batch_size=5, num_workers=4, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "# Create DenseNet121 based model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = monai.networks.nets.DenseNet121(spatial_dims=3, in_channels=1, out_channels=3).to(device) #Out channels önemli  DenseNet121\n",
    "\n",
    "model.load_state_dict(torch.load(\"/content/drive/MyDrive/best_metric_files/best_metric_model_classification3d_array_4.pth\"))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    num_correct = 0.0\n",
    "    metric_count = 0\n",
    "    saver = CSVSaver(output_dir=\"./output\")\n",
    "    for val_data in val_loader:\n",
    "        val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "        val_outputs = model(val_images).argmax(dim=1)\n",
    "        value = torch.eq(val_outputs, val_labels)\n",
    "        metric_count += len(value)\n",
    "        num_correct += value.sum().item()\n",
    "        saver.save_batch(val_outputs, val_data[2])\n",
    "    metric = num_correct / metric_count\n",
    "    print(\"evaluation metric:\", metric)\n",
    "    print(\"Number of Corrects:\",num_correct)\n",
    "    saver.finalize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
