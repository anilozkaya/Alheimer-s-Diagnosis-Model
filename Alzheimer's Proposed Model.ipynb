{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad14d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install SimpleITK\n",
    "pip install dltk\n",
    "pip install nipype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573fbc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces import fsl\n",
    "from nipype.testing import example_data\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from dltk.io.augmentation import *\n",
    "from dltk.io.preprocessing import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import skimage\n",
    "from skimage import data\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d4c68a",
   "metadata": {},
   "source": [
    "# Generate CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8851a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is no a csv file for the data, it can be created by using the code below. Data should be in folders according to their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea079c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Files should be separated according to their label. Filenames must be the same as label.\n",
    "def get_images(dir_name=r'./test or train'):\n",
    "    \n",
    "\n",
    "    img_names=[]\n",
    "    \n",
    "    for label_name in os.listdir(dir_name):\n",
    "        for img_file_name in os.listdir('/'.join([dir_name, label_name])):\n",
    "            img_names.append([img_file_name, label_name])\n",
    "\n",
    "    return img_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6cf9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names= get_images(\"./test\")\n",
    "#Create dataframe and csv\n",
    "df = pd.DataFrame(img_names, columns=['img_file_name', 'label_name']) # create a dataframe from match list\n",
    "df.to_csv(\"test.csv\", index=False) # create csv from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9c31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names= get_images(\"./train\")\n",
    "#Create dataframe and csv\n",
    "df = pd.DataFrame(img_names, columns=['img_file_name', 'label_name']) # create a dataframe from match list\n",
    "df.to_csv(\"train.csv\", index=False) # create csv from df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d6f1c9",
   "metadata": {},
   "source": [
    "# Prepare The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bf499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "\n",
    "#Unzip the FSL zip files\n",
    "\n",
    "for filename in os.listdir('./skull_stripped_test'): \n",
    "  with gzip.open(os.path.join('./skull_stripped_test', filename), 'rb') as f_in:\n",
    "      with open(os.path.join('./test_unzipped_preprocessed', filename.replace(\".gz\",\"\")), 'wb') as f_out:\n",
    "         shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d78fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('./skull_stripped_train'): \n",
    "  with gzip.open(os.path.join('./skull_stripped_train', filename), 'rb') as f_in:\n",
    "      with open(os.path.join('./train_unzipped_preprocessed', filename.replace(\".gz\",\"\")), 'wb') as f_out:\n",
    "         shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa9f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For The Training Data\n",
    "\n",
    "# Prepare and organize the images\n",
    "path='./train_unzipped_preprocessed'\n",
    "for filename in os.listdir(path):   \n",
    "        complete_file_path = os.path.join(path, filename)  # filename\n",
    "        # load sitk image\n",
    "        sitk_moving = sitk.ReadImage(complete_file_path)\n",
    "        \n",
    "        t1 = sitk.GetArrayFromImage(sitk_moving)\n",
    "        # Resizing image to [128, 256, 256] required padding\n",
    "        #t1_padded = resize_image_with_crop_or_pad(t1, [128, 128, 128], mode='symmetric')\n",
    "        sitk_moving=skimage.transform.resize(t1, [128, 128, 128])\n",
    "        t1_norm_zo = normalise_zero_one(sitk_moving) #Diğer koddan alındı\n",
    "        \n",
    "        # Crop to [64, 64, 64]\n",
    "        #t1_cropped = resize_image_with_crop_or_pad(t1, [64, 64, 64], mode='symmetric')\n",
    "\n",
    "\n",
    "        # Add a feature dimension and normalise\n",
    "        #t1_norm = np.expand_dims(normalise_one_one(t1_slice), axis=-1)\n",
    "\n",
    "        # Randomly flip the image along axis 1\n",
    "        #t1_flipped = flip(t1_norm_zo.copy(), axis=1)\n",
    "\n",
    "        # Add a Gaussian offset (independently for each channel)\n",
    "        #t1_offset = add_gaussian_offset(t1_norm_zo.copy(), sigma=0.5)\n",
    "\n",
    "        # Add Gaussian noise\n",
    "        #t1_noise = add_gaussian_noise(t1_norm_zo.copy(), sigma=0.25)\n",
    "\n",
    "        # Elastic transforms. Alpha and sigma parameters \n",
    "        #t1_trans_low_s = elastic_transform(t1_norm.copy(), alpha=[1, 1e5, 1e5], sigma=[1, 10, 10])\n",
    "        #t1_trans_high_s = elastic_transform(t1_norm.copy(), alpha=[10, 2e6, 2e6], sigma=[1, 25, 25])\n",
    "\n",
    "\n",
    "        new_image=sitk.GetImageFromArray(t1_norm_zo)\n",
    "        \n",
    "        # prepare the destination path\n",
    "        complete_new_path = os.path.join('./train_dataset_preprocessed', \n",
    "                                        filename)  #filename\n",
    "        sitk.WriteImage(new_image, complete_new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c57f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For The Test Data\n",
    "\n",
    "\n",
    "# Prepare and organize the images\n",
    "path='./test_unzipped_preprocessed'\n",
    "#for files in os.walk(DATABASE):\n",
    "for filename in os.listdir(path):   \n",
    "    #for filename in os.listdir(os.path.join(path, classname)):\n",
    "        complete_file_path = os.path.join(path, filename)  # filename\n",
    "        # load sitk image\n",
    "        sitk_moving = sitk.ReadImage(complete_file_path)\n",
    "        \n",
    "        # Resizing image to [128, 256, 256] required padding\n",
    "        \n",
    "        t1 = sitk.GetArrayFromImage(sitk_moving)\n",
    "        #t1_padded = resize_image_with_crop_or_pad(t1, [128, 128, 128], mode='symmetric')\n",
    "\n",
    "        sitk_moving=skimage.transform.resize(t1, [128, 128, 128])\n",
    "        t1_norm_zo = normalise_zero_one(sitk_moving) #Diğer koddan alındı\n",
    "        \n",
    "        # Crop function to [64, 64, 64] can be changed\n",
    "        #t1_cropped = resize_image_with_crop_or_pad(t1, [64, 64, 64], mode='symmetric')\n",
    "\n",
    "\n",
    "        # Add a feature dimension and normalise\n",
    "        #t1_norm = np.expand_dims(normalise_one_one(t1_slice), axis=-1)\n",
    "\n",
    "        # Randomly flip the image along axis 1\n",
    "        #t1_flipped = flip(t1_norm_zo.copy(), axis=1)\n",
    "\n",
    "        # Add a Gaussian offset (independently for each channel)\n",
    "        #t1_offset = add_gaussian_offset(t1_norm_zo.copy(), sigma=0.5)\n",
    "\n",
    "        # Add Gaussian noise\n",
    "        #t1_noise = add_gaussian_noise(t1_norm_zo.copy(), sigma=0.25)\n",
    "\n",
    "        # Elastic transforms. Alpha and sigma parameters \n",
    "        #t1_trans_low_s = elastic_transform(t1_norm.copy(), alpha=[1, 1e5, 1e5], sigma=[1, 10, 10])\n",
    "        #t1_trans_high_s = elastic_transform(t1_norm.copy(), alpha=[10, 2e6, 2e6], sigma=[1, 25, 25])\n",
    "\n",
    "\n",
    "        new_image=sitk.GetImageFromArray(t1_norm_zo)\n",
    "\n",
    "\n",
    "        # Prepare the destination path\n",
    "        complete_new_path = os.path.join('./test_dataset_preprocessed', \n",
    "                                        filename)  #filename\n",
    "        sitk.WriteImage(new_image, complete_new_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9d2e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = r'./train_dataset_preprocessed'\n",
    "str = \"_brain\"\n",
    "for filename in os.listdir(rootdir):\n",
    "    if str in filename:    \n",
    "        filepath = os.path.join(rootdir, filename)\n",
    "        newfilepath = os.path.join(rootdir, filename.replace(str, \"\"))\n",
    "        os.rename(filepath, newfilepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61102c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = r'./test_dataset_preprocessed'\n",
    "str = \"_brain\"\n",
    "for filename in os.listdir(rootdir):\n",
    "    if str in filename:    \n",
    "        filepath = os.path.join(rootdir, filename)\n",
    "        newfilepath = os.path.join(rootdir, filename.replace(str, \"\"))\n",
    "        os.rename(filepath, newfilepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0b466e",
   "metadata": {},
   "source": [
    "# Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3af139",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install monai\n",
    "pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910712f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import monai\n",
    "from monai.data import ImageDataset\n",
    "from monai.transforms import AddChannel, Compose, RandRotate90, Resize, ScaleIntensity, EnsureType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5aa5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import summary\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7efd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_class = {\n",
    "    'NC': 0,\n",
    "    'MCI': 1,\n",
    "    'AD': 2,\n",
    "    #Extra classes can be added\n",
    "    #'NewClass':3\n",
    "    \n",
    "}\n",
    "class_to_label = {v: k for k, v in label_to_class.items()}\n",
    "n_classes = len(label_to_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db112b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "monai.config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "images = []\n",
    "labels=[]\n",
    "train_image_count=160   #How many images are in the training dataset?\n",
    "\n",
    "image_labels= pd.read_csv(\"./train.csv\")\n",
    "image_labels = image_labels.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "for index in range(train_image_count-1):\n",
    "  labels.append(label_to_class[image_labels.iloc[index, 1]])\n",
    "  images.append(os.path.join(\"./train_dataset_preprocessed\",image_labels.iloc[index,0])) \n",
    "\n",
    "labels = np.array(labels)\n",
    "image_file_names=image_labels.iloc[index,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9955adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6054d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781efca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=50\n",
    "#split için değişken oluştur\n",
    "\n",
    "# Define Training and Validation transforms\n",
    "train_transforms = Compose([ScaleIntensity(), AddChannel(), RandRotate90(), EnsureType()])  \n",
    "valid_transforms = Compose([ScaleIntensity(), AddChannel(),  EnsureType()])   \n",
    "\n",
    "# Define image dataset, data loader\n",
    "check_ds = ImageDataset(image_files=images, labels=labels,transform=train_transforms)\n",
    "check_dataloader = DataLoader(check_ds, batch_size=2, number_of_workers=2, pin_memory=torch.cuda.is_available())\n",
    "im, label = monai.utils.misc.first(check_dataloader)\n",
    "print(type(im), im.shape, label)\n",
    "\n",
    "# Create a training data loader. The number of images to be used should be written.\n",
    "train_dataset= ImageDataset(image_files=images[:144], labels=labels[:144], transform=train_transforms)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=7, shuffle=True, number_of_workers=2, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "# create a validation data loader. The number of images to be used should be written.\n",
    "valid_dataset = ImageDataset(image_files=images[-15:], labels=labels[-15:], transform=valid_transforms)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=5, shuffle=True, number_of_workers=2, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "# Create DenseNet121, CrossEntropyLoss and Adam optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "alz_model = monai.networks.nets.DenseNet121(spatial_dims=3,in_channels=1, out_channels=3 ).to(device)  \n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "#Starting learning rate is 1e-7 default\n",
    "optimizer = torch.optim.Adam(alz_model.parameters(),lr=1e-7 ) \n",
    "#Max learning rate can be changed according to data\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-5 , steps_per_epoch=len(train_dataloader), epochs=num_epochs)\n",
    "\n",
    "valid_interval = 2\n",
    "best_metric = -1\n",
    "epoch_loss_list = list()\n",
    "metric_values = list()\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33021dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(alz_model)\n",
    "batch_size = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14295a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir /content/runs/RunFileMustBeAdded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e162d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_model_training_loss_ls = []\n",
    "validation_model_training_accuracy_ls = []\n",
    "\n",
    "for current_epoch in range(num_epochs):\n",
    "      print(\"-\" * 10)\n",
    "      print(f\"epoch {current_epoch + 1}/{num_epochs}\")\n",
    "      alz_model.train()\n",
    "      epoch_loss = 0\n",
    "      epoch_valid_loss=0\n",
    "      train_step = 0\n",
    "      valid_step=0\n",
    "      for batch_data in train_dataloader:\n",
    "          train_step += 1\n",
    "          inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "          outputs = alz_model(inputs)\n",
    "          loss = loss_function(outputs, labels)\n",
    "          loss.backward()\n",
    "          optimizer.zero_grad()\n",
    "          optimizer.train_step()\n",
    "          scheduler.train_step()\n",
    "          curr_lr = optimizer.param_groups[0][\"lr\"]\n",
    "          epoch_loss += loss.item()\n",
    "          epoch_len = len(train_dataset) // train_dataloader.batch_size\n",
    "          print(f\"{train_step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "          writer.add_scalar(\"train_loss\", loss.item(), epoch_len * current_epoch + train_step)\n",
    "          writer.add_scalar(\"learning_rate\",  curr_lr, epoch_len * current_epoch + train_step)\n",
    "      epoch_loss /= train_step\n",
    "      epoch_loss_list.append(epoch_loss)\n",
    "      print(f\"epoch {current_epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "      #writer.add_scalar(\"total_train_loss\", epoch_loss, epoch_len * current_epoch + train_step)\n",
    "\n",
    "      if (current_epoch + 1) % valid_interval == 0:\n",
    "          alz_model.eval()\n",
    "          with torch.no_grad():\n",
    "              num_of_correct = 0.0\n",
    "              metric_count = 0\n",
    "              for valid_data in valid_dataloader:\n",
    "                  valid_step=valid_step+1\n",
    "                  valid_images, valid_labels = valid_data[0].to(device), valid_data[1].to(device)\n",
    "                  valid_outputs = alz_model(valid_images)\n",
    "                  value = torch.eq(valid_outputs.argmax(dim=1), valid_labels)\n",
    "                  metric_count += len(value)\n",
    "                  num_of_correct += value.sum().item()\n",
    "                  \n",
    "                  validation_loss_local_train_fn = loss_function(valid_outputs, valid_labels)\n",
    "                  epoch_valid_loss += validation_loss_local_train_fn.item()\n",
    "                  print(f\"{train_step}/{epoch_len}, valid_loss: {validation_loss_local_train_fn.item():.4f}\")\n",
    "                  writer.add_scalar(\"valid_loss\", validation_loss_local_train_fn.item(), epoch_len * current_epoch + train_step)\n",
    "              metric = num_of_correct / metric_count\n",
    "              metric_values.append(metric)\n",
    "              epoch_valid_loss /= valid_step\n",
    "              epoch_loss_list.append(epoch_valid_loss)\n",
    "              print(f\"epoch {current_epoch + 1} average validation loss: {epoch_valid_loss:.4f}\")\n",
    "              \n",
    "              if metric > best_metric:\n",
    "                  best_metric = metric\n",
    "                  best_metric_epoch = current_epoch + 1\n",
    "                  torch.save(alz_model.state_dict(), \"./best_metric_model_classification_3d_array.pth\")\n",
    "                  print(\"New best metric model is saved\")\n",
    "              print(\n",
    "                  \"current epoch: {} current accuracy: {:.4f} best accuracy: {:.4f} at epoch {}\".format(\n",
    "                      current_epoch + 1, metric, best_metric, best_metric_epoch\n",
    "                  )\n",
    "              )\n",
    "              writer.add_scalar(\"valid_accuracy\", metric, current_epoch + 1)\n",
    "              \n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bcec2c",
   "metadata": {},
   "source": [
    "# Evaluation Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf2bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import monai\n",
    "from monai.data import CSVSaver, ImageDataset\n",
    "from monai.transforms import AddChannel, Compose, Resize, ScaleIntensity, EnsureType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52604ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "monai.config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "test_image_count=40 #How many images are in the test dataset\n",
    "image_labels= pd.read_csv(\"./test.csv\")\n",
    "\n",
    "for index in range(test_image_count-1):\n",
    "  labels.append(label_to_class[image_labels.iloc[index, 1]])\n",
    "  images.append(os.path.join(\"./test_dataset_preprocessed\",\n",
    "                                    image_labels.iloc[index,0]))  \n",
    "\n",
    "labels = np.array(labels)\n",
    "# Define transforms for images\n",
    "valid_transforms = Compose([ScaleIntensity(), AddChannel(),  EnsureType()]) \n",
    "\n",
    "# Validation image dataset\n",
    "valid_dataset = ImageDataset(image_files=images, labels=labels, transform=valid_transforms, image_only=False)\n",
    "# Validation data loader for validation dataset\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=5, number_of_workers=4, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "# Creating a DenseNet121 architecture based model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "alz_model = monai.networks.nets.DenseNet121(spatial_dims=3, in_channels=1, out_channels=3).to(device) #Out channels should be equal to class number\n",
    "\n",
    "alz_model.load_state_dict(torch.load(\"./best_metric_model_classification_3d_array.pth\"))\n",
    "alz_model.eval()\n",
    "with torch.no_grad():\n",
    "    num_of_correct = 0.0\n",
    "    metric_count = 0\n",
    "    csv_saver = CSVSaver(output_dir=\"./output\")\n",
    "    for valid_data in valid_dataloader:\n",
    "        valid_images, valid_labels = valid_data[0].to(device), valid_data[1].to(device)\n",
    "        valid_outputs = alz_model(valid_images).argmax(dim=1)\n",
    "        value = torch.eq(valid_outputs, valid_labels)\n",
    "        metric_count += len(value)\n",
    "        num_of_correct += value.sum().item()\n",
    "        csv_saver.save_batch(valid_outputs, valid_data[2])\n",
    "    metric = num_of_correct / metric_count\n",
    "    print(\"Evaluation Metric:\", metric)\n",
    "    print(\"Number of Corrects:\",num_of_correct)\n",
    "    csv_saver.finalize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
